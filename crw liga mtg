import csv
import re
import requests
import unidecode
from bs4 import BeautifulSoup
from urllib.error import HTTPError, URLError
import pandas as pd

df_cartas = pd.read_csv('cartas.csv', index_col= None, names = ["cartas"])
cartas = df_cartas["cartas"].tolist()

output = list([["nome", "menorvalor", "maiorvalor"]])

for card in cartas:

  card = card.replace(" ","+")
  card = card.replace(",","%2C")

  website = ("https://www.ligamagic.com.br/?view=cards/card&card="+card)
  headers = {
              'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}
  print("Website:", website)
  page = requests.get(website, headers=headers, timeout=20)
  page = page.text
  soup = BeautifulSoup(page, 'lxml')

  nome = soup.find("title").get_text()
  nome = nome.replace(" | Busca de Cards | LigaMagic","")
  print(nome)

  trackpreco = soup.find("div", id="alerta-preco")
  menorpreco = trackpreco.find("div", class_="col-xl-6 col-6 b preco-menor")
  menorvalor = menorpreco.find("font", class_="bigger").get_text()
  print(menorvalor)
  maiorpreco = trackpreco.find("div", class_="col-xl-6 col-6 b preco-maior")
  maiorvalor = maiorpreco.find("font", class_="bigger").get_text()
  print(maiorvalor)

  linha_output =list([nome,menorvalor,maiorvalor])
  output.append(linha_output)
  df_output = pd.DataFrame(output, index=None, columns=None)
  df_output.to_csv('output.csv', index=False, na_rep="Unknown")

